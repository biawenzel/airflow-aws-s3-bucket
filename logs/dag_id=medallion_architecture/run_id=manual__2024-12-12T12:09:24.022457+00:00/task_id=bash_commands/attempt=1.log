[2024-12-12T09:09:53.359-0300] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-12-12T09:09:53.385-0300] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: medallion_architecture.bash_commands manual__2024-12-12T12:09:24.022457+00:00 [queued]>
[2024-12-12T09:09:53.410-0300] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: medallion_architecture.bash_commands manual__2024-12-12T12:09:24.022457+00:00 [queued]>
[2024-12-12T09:09:53.411-0300] {taskinstance.py:2303} INFO - Starting attempt 1 of 1
[2024-12-12T09:09:53.439-0300] {taskinstance.py:2327} INFO - Executing <Task(BashOperator): bash_commands> on 2024-12-12 12:09:24.022457+00:00
[2024-12-12T09:09:53.448-0300] {standard_task_runner.py:63} INFO - Started process 19672 to run task
[2024-12-12T09:09:53.448-0300] {clientserver.py:543} INFO - Closing down clientserver connection
[2024-12-12T09:09:53.452-0300] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'medallion_architecture', 'bash_commands', 'manual__2024-12-12T12:09:24.022457+00:00', '--job-id', '102', '--raw', '--subdir', 'DAGS_FOLDER/dag2.py', '--cfg-path', '/tmp/tmpm3t5npmf']
[2024-12-12T09:09:53.454-0300] {standard_task_runner.py:91} INFO - Job 102: Subtask bash_commands
[2024-12-12T09:09:53.488-0300] {task_command.py:426} INFO - Running <TaskInstance: medallion_architecture.bash_commands manual__2024-12-12T12:09:24.022457+00:00 [running]> on host beatriz-linux
[2024-12-12T09:09:53.566-0300] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='medallion_architecture' AIRFLOW_CTX_TASK_ID='bash_commands' AIRFLOW_CTX_EXECUTION_DATE='2024-12-12T12:09:24.022457+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-12T12:09:24.022457+00:00'
[2024-12-12T09:09:53.567-0300] {taskinstance.py:430} INFO - ::endgroup::
[2024-12-12T09:09:53.569-0300] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2024-12-12T09:09:53.570-0300] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', ('\nexport AWS_ACCESS_KEY_ID=ASIAWAA66KBX3CPJ4AHB;\nexport AWS_SECRET_ACCESS_KEY=***;\nexport AWS_SESSION_TOKEN=***;\nspark-submit --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.508 --conf spark.hadoop.fs.s3a.aws.credentials.provider=com.amazonaws.auth.DefaultAWSCredentialsProviderChain --conf spark.hadoop.fs.s3a.endpoint=s3.amazonaws.com --conf spark.hadoop.fs.s3a.region=us-east-1 ',)]
[2024-12-12T09:09:53.571-0300] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-12-12T09:09:53.571-0300] {taskinstance.py:2890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/beatriz/Documentos/airflow/airflow_venv/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/beatriz/Documentos/airflow/airflow_venv/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/beatriz/Documentos/airflow/airflow_venv/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
  File "/home/beatriz/Documentos/airflow/airflow_venv/lib/python3.10/site-packages/airflow/operators/bash.py", line 234, in execute
    result = self.subprocess_hook.run_command(
  File "/home/beatriz/Documentos/airflow/airflow_venv/lib/python3.10/site-packages/airflow/hooks/subprocess.py", line 77, in run_command
    self.sub_process = Popen(
  File "/usr/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/lib/python3.10/subprocess.py", line 1796, in _execute_child
    self.pid = _posixsubprocess.fork_exec(
TypeError: expected str, bytes or os.PathLike object, not set
[2024-12-12T09:09:53.577-0300] {taskinstance.py:1205} INFO - Marking task as FAILED. dag_id=medallion_architecture, task_id=bash_commands, execution_date=20241212T120924, start_date=20241212T120953, end_date=20241212T120953
[2024-12-12T09:09:53.605-0300] {standard_task_runner.py:110} ERROR - Failed to execute job 102 for task bash_commands (expected str, bytes or os.PathLike object, not set; 19672)
[2024-12-12T09:09:53.623-0300] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-12-12T09:09:53.636-0300] {taskinstance.py:3482} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-12-12T09:09:53.637-0300] {local_task_job_runner.py:222} INFO - ::endgroup::
