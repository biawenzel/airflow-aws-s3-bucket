[2024-12-11T15:24:19.419-0300] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-12-11T15:24:19.432-0300] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: medallion_architecture.task_spark_submit manual__2024-12-11T18:24:12.805318+00:00 [queued]>
[2024-12-11T15:24:19.436-0300] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: medallion_architecture.task_spark_submit manual__2024-12-11T18:24:12.805318+00:00 [queued]>
[2024-12-11T15:24:19.437-0300] {taskinstance.py:2303} INFO - Starting attempt 1 of 1
[2024-12-11T15:24:19.452-0300] {taskinstance.py:2327} INFO - Executing <Task(SparkSubmitOperator): task_spark_submit> on 2024-12-11 18:24:12.805318+00:00
[2024-12-11T15:24:19.459-0300] {clientserver.py:543} INFO - Closing down clientserver connection
[2024-12-11T15:24:19.458-0300] {standard_task_runner.py:63} INFO - Started process 35909 to run task
[2024-12-11T15:24:19.465-0300] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'medallion_architecture', 'task_spark_submit', 'manual__2024-12-11T18:24:12.805318+00:00', '--job-id', '56', '--raw', '--subdir', 'DAGS_FOLDER/dag2.py', '--cfg-path', '/tmp/tmp3_39jps4']
[2024-12-11T15:24:19.466-0300] {standard_task_runner.py:91} INFO - Job 56: Subtask task_spark_submit
[2024-12-11T15:24:19.491-0300] {task_command.py:426} INFO - Running <TaskInstance: medallion_architecture.task_spark_submit manual__2024-12-11T18:24:12.805318+00:00 [running]> on host beatriz-linux
[2024-12-11T15:24:19.548-0300] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='medallion_architecture' AIRFLOW_CTX_TASK_ID='task_spark_submit' AIRFLOW_CTX_EXECUTION_DATE='2024-12-11T18:24:12.805318+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-11T18:24:12.805318+00:00'
[2024-12-11T15:24:19.550-0300] {taskinstance.py:430} INFO - ::endgroup::
[2024-12-11T15:24:19.553-0300] {base.py:84} INFO - Using connection ID 'spark_default' for task execution.
[2024-12-11T15:24:19.554-0300] {spark_submit.py:473} INFO - Spark-Submit cmd: spark-submit --master yarn --conf spark.hadoop.fs.s3a.access.key=ASIAWAA66KBX3IICKJTU --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.endpoint=s3.amazonaws.com --jars /home/beatriz/spark-jars/hadoop-aws-3.3.4.jar,/home/beatriz/spark-jars/aws-java-sdk-bundle-1.12.508.jar --name arrow-spark --queue root.default /home/beatriz/Documentos/airflow/dags/tarefas/tarefas.py
[2024-12-11T15:24:21.034-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:21 WARN Utils: Your hostname, beatriz-linux resolves to a loopback address: 127.0.1.1; using 192.168.7.5 instead (on interface wlp0s20f3)
[2024-12-11T15:24:21.036-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
[2024-12-11T15:24:22.428-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:22 INFO SparkContext: Running Spark version 3.5.3
[2024-12-11T15:24:22.429-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:22 INFO SparkContext: OS info Linux, 6.8.0-49-generic, amd64
[2024-12-11T15:24:22.429-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:22 INFO SparkContext: Java version 11.0.25
[2024-12-11T15:24:22.465-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:22 INFO ResourceUtils: ==============================================================
[2024-12-11T15:24:22.466-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:22 INFO ResourceUtils: No custom resources configured for spark.driver.
[2024-12-11T15:24:22.466-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:22 INFO ResourceUtils: ==============================================================
[2024-12-11T15:24:22.467-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:22 INFO SparkContext: Submitted application: S3 Example
[2024-12-11T15:24:22.490-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:22 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2024-12-11T15:24:22.506-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:22 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
[2024-12-11T15:24:22.508-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:22 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2024-12-11T15:24:22.576-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:22 INFO SecurityManager: Changing view acls to: beatriz
[2024-12-11T15:24:22.576-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:22 INFO SecurityManager: Changing modify acls to: beatriz
[2024-12-11T15:24:22.577-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:22 INFO SecurityManager: Changing view acls groups to:
[2024-12-11T15:24:22.578-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:22 INFO SecurityManager: Changing modify acls groups to:
[2024-12-11T15:24:22.579-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: beatriz; groups with view permissions: EMPTY; users with modify permissions: beatriz; groups with modify permissions: EMPTY
[2024-12-11T15:24:22.843-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:22 INFO Utils: Successfully started service 'sparkDriver' on port 37063.
[2024-12-11T15:24:22.887-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:22 INFO SparkEnv: Registering MapOutputTracker
[2024-12-11T15:24:22.963-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:22 INFO SparkEnv: Registering BlockManagerMaster
[2024-12-11T15:24:22.999-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:22 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2024-12-11T15:24:23.000-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:23 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2024-12-11T15:24:23.045-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:23 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2024-12-11T15:24:23.068-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e090413b-e8c0-40ad-b508-7df008002421
[2024-12-11T15:24:23.083-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:23 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2024-12-11T15:24:23.133-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:23 INFO SparkEnv: Registering OutputCommitCoordinator
[2024-12-11T15:24:23.289-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:23 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2024-12-11T15:24:23.351-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[2024-12-11T15:24:23.352-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:23 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
[2024-12-11T15:24:23.360-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:23 INFO Utils: Successfully started service 'SparkUI' on port 4042.
[2024-12-11T15:24:23.582-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:23 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032
[2024-12-11T15:24:24.802-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:24 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:24:25.803-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:25 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:24:26.805-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:26 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:24:27.807-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:27 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:24:28.809-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:28 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:24:29.810-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:29 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:24:30.811-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:30 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:24:31.813-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:31 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:24:32.814-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:32 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:24:33.815-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:33 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:24:34.853-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:34 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:24:35.854-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:35 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:24:36.857-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:36 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:24:37.858-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:37 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:24:38.859-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:38 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:24:39.860-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:39 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:24:40.861-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:40 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:24:41.863-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:41 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:24:42.864-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:42 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:24:43.865-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:43 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:24:43.865-0300] {spark_submit.py:634} INFO - 24/12/11 15:24:43 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 1 failover attempts. Trying to failover after sleeping for 21626ms.
[2024-12-11T15:25:06.493-0300] {spark_submit.py:634} INFO - 24/12/11 15:25:06 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:25:07.493-0300] {spark_submit.py:634} INFO - 24/12/11 15:25:07 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:25:08.494-0300] {spark_submit.py:634} INFO - 24/12/11 15:25:08 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:25:09.495-0300] {spark_submit.py:634} INFO - 24/12/11 15:25:09 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:25:10.496-0300] {spark_submit.py:634} INFO - 24/12/11 15:25:10 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:25:11.497-0300] {spark_submit.py:634} INFO - 24/12/11 15:25:11 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:25:12.498-0300] {spark_submit.py:634} INFO - 24/12/11 15:25:12 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:25:13.498-0300] {spark_submit.py:634} INFO - 24/12/11 15:25:13 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:25:14.499-0300] {spark_submit.py:634} INFO - 24/12/11 15:25:14 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:25:15.500-0300] {spark_submit.py:634} INFO - 24/12/11 15:25:15 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:25:15.502-0300] {spark_submit.py:634} INFO - 24/12/11 15:25:15 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 2 failover attempts. Trying to failover after sleeping for 31753ms.
[2024-12-11T15:25:48.257-0300] {spark_submit.py:634} INFO - 24/12/11 15:25:48 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:25:49.258-0300] {spark_submit.py:634} INFO - 24/12/11 15:25:49 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:25:50.260-0300] {spark_submit.py:634} INFO - 24/12/11 15:25:50 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:25:51.261-0300] {spark_submit.py:634} INFO - 24/12/11 15:25:51 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:25:52.262-0300] {spark_submit.py:634} INFO - 24/12/11 15:25:52 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:25:53.264-0300] {spark_submit.py:634} INFO - 24/12/11 15:25:53 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:25:54.265-0300] {spark_submit.py:634} INFO - 24/12/11 15:25:54 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:25:55.266-0300] {spark_submit.py:634} INFO - 24/12/11 15:25:55 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:25:56.267-0300] {spark_submit.py:634} INFO - 24/12/11 15:25:56 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:25:57.268-0300] {spark_submit.py:634} INFO - 24/12/11 15:25:57 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:25:57.271-0300] {spark_submit.py:634} INFO - 24/12/11 15:25:57 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 3 failover attempts. Trying to failover after sleeping for 31107ms.
[2024-12-11T15:26:29.379-0300] {spark_submit.py:634} INFO - 24/12/11 15:26:29 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:26:30.381-0300] {spark_submit.py:634} INFO - 24/12/11 15:26:30 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:26:31.382-0300] {spark_submit.py:634} INFO - 24/12/11 15:26:31 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:26:32.383-0300] {spark_submit.py:634} INFO - 24/12/11 15:26:32 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:26:33.384-0300] {spark_submit.py:634} INFO - 24/12/11 15:26:33 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:26:34.385-0300] {spark_submit.py:634} INFO - 24/12/11 15:26:34 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:26:35.387-0300] {spark_submit.py:634} INFO - 24/12/11 15:26:35 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:26:36.389-0300] {spark_submit.py:634} INFO - 24/12/11 15:26:36 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:26:37.390-0300] {spark_submit.py:634} INFO - 24/12/11 15:26:37 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:26:38.391-0300] {spark_submit.py:634} INFO - 24/12/11 15:26:38 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:26:38.393-0300] {spark_submit.py:634} INFO - 24/12/11 15:26:38 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 4 failover attempts. Trying to failover after sleeping for 23262ms.
[2024-12-11T15:27:02.657-0300] {spark_submit.py:634} INFO - 24/12/11 15:27:02 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:27:03.658-0300] {spark_submit.py:634} INFO - 24/12/11 15:27:03 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:27:04.659-0300] {spark_submit.py:634} INFO - 24/12/11 15:27:04 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:27:05.661-0300] {spark_submit.py:634} INFO - 24/12/11 15:27:05 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:27:06.662-0300] {spark_submit.py:634} INFO - 24/12/11 15:27:06 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:27:07.664-0300] {spark_submit.py:634} INFO - 24/12/11 15:27:07 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:27:08.666-0300] {spark_submit.py:634} INFO - 24/12/11 15:27:08 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:27:09.668-0300] {spark_submit.py:634} INFO - 24/12/11 15:27:09 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:27:10.669-0300] {spark_submit.py:634} INFO - 24/12/11 15:27:10 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:27:11.670-0300] {spark_submit.py:634} INFO - 24/12/11 15:27:11 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:27:11.671-0300] {spark_submit.py:634} INFO - 24/12/11 15:27:11 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 5 failover attempts. Trying to failover after sleeping for 22565ms.
[2024-12-11T15:27:35.238-0300] {spark_submit.py:634} INFO - 24/12/11 15:27:35 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:27:36.240-0300] {spark_submit.py:634} INFO - 24/12/11 15:27:36 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:27:37.240-0300] {spark_submit.py:634} INFO - 24/12/11 15:27:37 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:27:38.241-0300] {spark_submit.py:634} INFO - 24/12/11 15:27:38 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:27:39.242-0300] {spark_submit.py:634} INFO - 24/12/11 15:27:39 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:27:40.244-0300] {spark_submit.py:634} INFO - 24/12/11 15:27:40 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:27:41.245-0300] {spark_submit.py:634} INFO - 24/12/11 15:27:41 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:27:42.246-0300] {spark_submit.py:634} INFO - 24/12/11 15:27:42 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:27:43.248-0300] {spark_submit.py:634} INFO - 24/12/11 15:27:43 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:27:44.250-0300] {spark_submit.py:634} INFO - 24/12/11 15:27:44 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-12-11T15:27:44.252-0300] {spark_submit.py:634} INFO - 24/12/11 15:27:44 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 6 failover attempts. Trying to failover after sleeping for 37729ms.
[2024-12-11T15:28:06.499-0300] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-12-11T15:28:06.510-0300] {process_utils.py:132} INFO - Sending 15 to group 35909. PIDs of all processes in the group: [35910, 35986, 35909]
[2024-12-11T15:28:06.511-0300] {process_utils.py:87} INFO - Sending the signal 15 to group 35909
[2024-12-11T15:28:06.512-0300] {taskinstance.py:2607} ERROR - Received SIGTERM. Terminating subprocesses.
[2024-12-11T15:28:06.513-0300] {spark_submit.py:760} INFO - Sending kill signal to spark-submit
[2024-12-11T15:28:06.514-0300] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-12-11T15:28:06.519-0300] {process_utils.py:80} INFO - Process psutil.Process(pid=35986, status='terminated', started='15:24:21') (35986) terminated with exit code None
[2024-12-11T15:28:06.523-0300] {taskinstance.py:2890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/beatriz/Documentos/airflow/airflow_venv/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/beatriz/Documentos/airflow/airflow_venv/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/beatriz/Documentos/airflow/airflow_venv/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
  File "/home/beatriz/Documentos/airflow/airflow_venv/lib/python3.10/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 176, in execute
    self._hook.submit(self.application)
  File "/home/beatriz/Documentos/airflow/airflow_venv/lib/python3.10/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 548, in submit
    self._process_spark_submit_log(iter(self._submit_sp.stdout))  # type: ignore
  File "/home/beatriz/Documentos/airflow/airflow_venv/lib/python3.10/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 597, in _process_spark_submit_log
    for line in itr:
  File "/home/beatriz/Documentos/airflow/airflow_venv/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 2609, in signal_handler
    raise AirflowTaskTerminated("Task received SIGTERM signal")
airflow.exceptions.AirflowTaskTerminated: Task received SIGTERM signal
[2024-12-11T15:28:06.532-0300] {taskinstance.py:1205} INFO - Marking task as FAILED. dag_id=medallion_architecture, task_id=task_spark_submit, execution_date=20241211T182412, start_date=20241211T182419, end_date=20241211T182806
[2024-12-11T15:28:06.572-0300] {process_utils.py:80} INFO - Process psutil.Process(pid=35909, status='terminated', exitcode=2, started='15:24:19') (35909) terminated with exit code 2
[2024-12-11T15:28:06.573-0300] {process_utils.py:80} INFO - Process psutil.Process(pid=35910, status='terminated', started='15:24:19') (35910) terminated with exit code None
